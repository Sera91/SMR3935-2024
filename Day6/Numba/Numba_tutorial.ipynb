{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PR0Ga9oNX5R"
      },
      "source": [
        "Numba is a just-in-time, type-specializing, function compiler.\n",
        "Numba is one of the most commonly used libraries nowadays to speed-up python code. It can speed up your existing python code by a big margin by simply decorating your existing functions with numba decorators. Numba provides various decorators to speed up the python code.\n",
        "\n",
        "The more important decorators in Numba are\n",
        "\n",
        "- @jit &@njit  - to speed up almost any python function.\n",
        "- @vectorize   - to speed up numpy-like universal functions.\n",
        "- @guvectorize - extended version of @vectorize decorator.\n",
        "- @stencil     - to speed up function performing stencil kernel operations (e.g convolutions)\n",
        "\n",
        "The Numba @jit decorator fundamentally operates in two compilation modes, nopython mode and object mode\n",
        "\n",
        "The behaviour of the nopython compilation mode is to essentially compile the decorated function so that it will run entirely without the involvement of the Python interpreter. This is the recommended and best-practice way to use the Numba jit decorator as it leads to the best performance.\n",
        "\n",
        "The @vectorize decorator requires us to specify possible data types of input and output of the function, in order to create a compiled version for each data type.\n",
        "\n",
        "Apart from datatypes, it accepts two other arguments:\n",
        "\n",
        "-   target\n",
        "-   cache - boolean parameter specifying whether to use caching to speed up reruns of the same function again and again with the same inputs.\n",
        "\n",
        "\n",
        "The target argument accepts one string as input specifying how to further speed up code based on available resources:\n",
        "\n",
        "- 'cpu' - This is default argument. It's used for a single-core (single-threaded) CPU.\n",
        "- 'parallel' - This argument runs code in parallel on multi-core (multi-threaded) CPU.\n",
        "- 'cuda' - This argument is set for GPU\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "@vectorize([ret_datatype1(input1_datatype1,input2_datatype1,...), ret_datatype2(input1_datatype2,input2_datatype2,...), ...], target='cpu', cache=False)\n",
        "def func(x):\n",
        "    return x*x\n",
        "```\n",
        "\n",
        "NOTE: The data type should be in order from less memory data type to more memory data type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX0EMoZYOAdQ",
        "outputId": "555f270f-6d3a-4b05-84b0-cfd571b21d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numba Version : 0.58.1\n"
          ]
        }
      ],
      "source": [
        "import numba\n",
        "\n",
        "print(\"Numba Version : {}\".format(numba.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "ilqJQjinZPNi",
        "outputId": "052348f3-c0cd-48f3-92fe-4f7a8e49066a"
      },
      "outputs": [],
      "source": [
        "\n",
        "@numba.njit\n",
        "def plus1(x):\n",
        "    return x + 1\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "plus1(np.arange(10))\n",
        "plus1.signatures\n",
        "\n",
        "\n",
        "#Inspecting LLVM control graph\n",
        "#plus1.inspect_cfg(plus1.signatures[0]).display()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@njit\n",
        "def foo(x):\n",
        "    if x < 3:\n",
        "        return x + 1\n",
        "    return x + 2\n",
        "\n",
        "foo(10)\n",
        "\n",
        "#print(foo.inspect_disasm_cfg(signature=foo.signatures[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF_LfQf1L0RM",
        "outputId": "d852b19b-243a-403d-95ee-7a928f92c945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203\n",
            "793 ms ± 4.32 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "from numba import jit\n",
        "from numba import vectorize, int64, float32, float64\n",
        "\n",
        "def cube_formula(x):\n",
        "    return x**3 + 3*x**2 + 3\n",
        "\n",
        "#cube_formula_jitted = jit(cube_formula)\n",
        "\n",
        "print(cube_formula(5))\n",
        "\n",
        "\n",
        "#NUMPY VECTORIZE\n",
        "vectorized_cube_formula = np.vectorize(cube_formula)\n",
        "arr = np.arange(1, 1000000, dtype=np.int64)\n",
        "\n",
        "\n",
        "%timeit vectorized_cube_formula(arr)\n",
        "\n",
        "#print(\"The time taken with numpy vectorize is \",timeit.timeit(stmt='vectorized_cube_formula(arr)',globals=globals()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIoOr70KPEUM",
        "outputId": "0b1b4cc5-36fa-4dbc-c6a9-32e479e05747"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-7af0043bb171>:4: NumbaDeprecationWarning: The keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
            "  @jit(nopython=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time taken with Numba jit is:\n",
            "\n",
            "25.7 ms ± 332 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "The time taken with Numba jit, in nopython mode, is \n",
            "\n",
            "27 ms ± 509 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "arr = np.arange(1, 1000000, dtype=np.int64)\n",
        "\n",
        "\n",
        "@jit(nopython=False)\n",
        "def cube_formula_jitted(x):\n",
        "    xs = []\n",
        "    for i in x:\n",
        "        xs.append(i**3 + 3*i**2 + 3)\n",
        "    return xs\n",
        "\n",
        "res = cube_formula_jitted(arr)\n",
        "\n",
        "\n",
        "print(\"The time taken with Numba jit is:\\n\")\n",
        "%timeit cube_formula_jitted(arr)\n",
        "#print(timeit.timeit('cube_formula_jitted(arr)', globals=globals()))\n",
        "\n",
        "@jit(nopython=True)\n",
        "def new_cube_formula_jitted(x):\n",
        "    xs = []\n",
        "    for i in x:\n",
        "        xs.append(i**3 + 3*i**2 + 3)\n",
        "    return xs\n",
        "\n",
        "print(\"The time taken with Numba jit, in nopython mode, is \\n\")\n",
        "%timeit new_cube_formula_jitted(arr)\n",
        "\n",
        "#in python script you can use\n",
        "#print(\"The time taken with Numba jit is \",timeit.timeit('arr = np.arange(1, 1000000, dtype=np.int64); new_cube_formula_jitted(arr)', setup=\"from __main__ import new_cube_formula_jitted\"))\n",
        "#print(\"The time taken with Numba jit, in nopython mode, is \",timeit.timeit(stmt='new_cube_formula_jitted(arr)', globals=globals()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopONo1wOXJ9",
        "outputId": "d3a38180-0597-4394-f01d-02ba024f4df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time taken with Numba vectorize is: \n",
            " \n",
            "633 µs ± 23 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "@vectorize([int64(int64), float32(float32), float64(float64)])\n",
        "def cube_formula_numba_vec(x):\n",
        "    return x**3 + 3*x**2 + 3\n",
        "\n",
        "\n",
        "print(\"The time taken with Numba vectorize is: \\n \")\n",
        "\n",
        "%timeit cube_formula_numba_vec(arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK7MPYfXOX6I",
        "outputId": "9d5e55c2-8323-4fb8-faff-75e5de874a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time taken with Numba vectorize parallelized is: \n",
            " \n",
            "170 µs ± 3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "#NUMBA PARALLELIZED with multithreading\n",
        "\n",
        "@vectorize([int64(int64), float32(float32), float64(float64)], target=\"parallel\")\n",
        "def cube_formula_numba_vec_paralleled(x):\n",
        "    return x**3 + 3*x**2 + 3\n",
        "\n",
        "\n",
        "\n",
        "print(\"The time taken with Numba vectorize parallelized is: \\n \")\n",
        "\n",
        "%timeit cube_formula_numba_vec_paralleled(arr)\n",
        "\n",
        "#print(\"The time taken with Numba jit is \",timeit.timeit(stmt='cube_formula_numba_vec_paralleled(arr)', globals=globals()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8a-i2z5OYrP",
        "outputId": "ef45fa68-cfa1-4bf4-a1c8-f0603f7b16b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time taken with Numba vectorize cached is: \n",
            " \n",
            "646 µs ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "#Caching in Numba\n",
        "@vectorize([int64(int64), float32(float32), float64(float64)], cache=True)\n",
        "def cube_formula_numba_vec_cached(x):\n",
        "    return x**3 + 3*x**2 + 3\n",
        "\n",
        "print(\"The time taken with Numba vectorize cached is: \\n \")\n",
        "\n",
        "%timeit cube_formula_numba_vec_cached(arr)\n",
        "\n",
        "#print(\"The time taken with numpy vectorize is \",timeit.timeit(stmt='cube_formula_numba_vec_cached(arr)'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EXCoM5Ga0jp"
      },
      "outputs": [],
      "source": [
        "#EXERCISE: Given the serial recursive function to build the Fibonacci sequence, defined below, use numba decorators to speed up the function and time the different decoreated versions.\n",
        "\n",
        "def Fibonacci():\n",
        "\n",
        "\n",
        "#Question: Is the caching utility useful in this case? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sjb6wu3OZeE"
      },
      "source": [
        "# Numba on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEfQ5DXPZ5Ho"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "\n",
        "from numba import cuda, float32\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tya87_DqZpV0"
      },
      "outputs": [],
      "source": [
        "#Vector Addition with Numba on GPU\n",
        "\n",
        "@cuda.jit\n",
        "def f(a, b, c):\n",
        "\n",
        "    # like threadIdx.x + (blockIdx.x * blockDim.x)\n",
        "\n",
        "    tid = cuda.grid(1)\n",
        "\n",
        "    size = len(c)\n",
        "\n",
        "\n",
        "    if tid < size:\n",
        "\n",
        "        c[tid] = a[tid] + b[tid]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn4M_2zIaXYN"
      },
      "source": [
        "We have two ways to launch this kernel:\n",
        "- defining the cuda grid size (the number of threads)\n",
        "- using for all construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBscAB37aAC8"
      },
      "outputs": [],
      "source": [
        "#WAY 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6-bwPF_BMH0-"
      },
      "outputs": [],
      "source": [
        "#Matrix multiplication\n",
        "@cuda.jit\n",
        "def matmul(A, B, C):\n",
        "\n",
        "    \"\"\"Perform square matrix multiplication of C = A * B.\"\"\"\n",
        "\n",
        "    i, j = cuda.grid(2)\n",
        "\n",
        "    if i < C.shape[0] and j < C.shape[1]:\n",
        "\n",
        "        tmp = 0.\n",
        "\n",
        "        for k in range(A.shape[1]):\n",
        "\n",
        "            tmp += A[i, k] * B[k, j]\n",
        "\n",
        "        C[i, j] = tmp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyvApdGzMeTq",
        "outputId": "64cb4725-0830-4459-f6b8-47c7fef0adde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n",
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "x_h = np.arange(16).reshape([4, 4])\n",
        "y_h = np.ones([4, 4])\n",
        "z_h = np.zeros([4, 4])\n",
        "\n",
        "\n",
        "#Moving numpy arrays to GPU\n",
        "x_d = cuda.to_device(x_h)\n",
        "y_d = cuda.to_device(y_h)\n",
        "z_d = cuda.to_device(z_h)\n",
        "\n",
        "\n",
        "#defining the grid on the GPU, using 16 threads per block\n",
        "threadsperblock = (32, 32)\n",
        "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "#performing the matmul\n",
        "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
        "\n",
        "#copying the output array back to the CPU\n",
        "z_h = z_d.copy_to_host()\n",
        "\n",
        "print(z_h)\n",
        "\n",
        "print(x_h @ y_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwoV-I9eNFsd",
        "outputId": "bea41c41-4f12-4290-eb4c-8ceb1e0ae201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59.2 µs ± 658 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVR5GVWXNRuZ"
      },
      "outputs": [],
      "source": [
        "#COMPARE the execution time with Cupy matmul"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
